{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Shape: (401682, 239)\n",
      "Processed DataFrame shape: (401682, 51)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, \n",
    "                             recall_score, roc_auc_score, mean_squared_error, r2_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import math\n",
    "\n",
    "from config import region_mapping, set1, to_model_a, to_model_c, to_model_ac, to_model\n",
    "\n",
    "# Define functions\n",
    "\n",
    "\n",
    "def get_existing_file_path(*paths):\n",
    "    \"\"\"Checks and returns the first existing file path from the given list of paths.\"\"\"\n",
    "    for path in paths:\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None\n",
    "\n",
    "def invert_region_mapping(mapping):\n",
    "    \"\"\"Inverts a region to country mapping to a country to region mapping.\"\"\"\n",
    "    return {country: region for region, countries in mapping.items() for country in countries}\n",
    "\n",
    "\n",
    "def read_and_process_data(file_path, columns, region_mapping):\n",
    "    \"\"\"Reads data from CSV, maps countries to regions, and selects specified columns.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "        print(f\"Data loaded. Shape: {df.shape}\")\n",
    "\n",
    "        country_to_region = invert_region_mapping(region_mapping)\n",
    "        df['Region'] = df['Country'].map(country_to_region)\n",
    "\n",
    "        df_processed = df[columns].copy()\n",
    "        df_processed.loc[:, 'Processed food in diet'] = df_processed['Processed food in diet'].replace({\n",
    "            'Rarely/never': 'Rarely/Never',\n",
    "            'A few times in a day': 'Several times a day',\n",
    "            'Several days a week': 'A few times a week',\n",
    "            'Many times in a day': 'Several times a day',\n",
    "            'At least once a day': 'Several times a day'\n",
    "        })\n",
    "\n",
    "        return df_processed\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define file paths\n",
    "path = '/Users/jerzybala/Desktop/Simulation Experiments Aug-Sep 2023/PROCESSED_FOOD_Dec2023.csv'\n",
    "path2 = '/Volumes/Desktop/Simulation Experiments Aug-Sep 2023/PROCESSED_FOOD_Dec2023.csv'\n",
    "\n",
    "# Determine which file path exists\n",
    "file_path = get_existing_file_path(path, path2)\n",
    "\n",
    "# Process the data if file exists\n",
    "if file_path:\n",
    "    df_org2 = read_and_process_data(file_path, set1, region_mapping)\n",
    "    print(f\"Processed DataFrame shape: {df_org2.shape}\\n\")\n",
    "else:\n",
    "    print(\"File not found in the given paths.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rarely/Never           154981\n",
      "A few times a month    125715\n",
      "A few times a week      85120\n",
      "Once a day              19340\n",
      "Several times a day     16526\n",
      "Name: Processed food in diet, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def update_food_category_based_on_modes(df, source_cat, target_cat, features):\n",
    "    \"\"\"\n",
    "    Updates 'Processed food in diet' category in the DataFrame based on mode matching.\n",
    "    \n",
    "    :param df: DataFrame to be processed.\n",
    "    :param source_cat: The category to analyze for mode (e.g., 'Rarely/Never').\n",
    "    :param target_cat: The category to update to (e.g., 'Once a day').\n",
    "    :param features: List of features to calculate mode and match against.\n",
    "    :return: DataFrame with updated 'Processed food in diet' values.\n",
    "    \"\"\"\n",
    "    def calculate_modes(dataframe, category, feature_list):\n",
    "        category_df = dataframe[dataframe['Processed food in diet'] == category]\n",
    "        return {feature: category_df[feature].mode()[0] for feature in feature_list}\n",
    "\n",
    "    def matches_modes(row, modes):\n",
    "        return sum(row[feature] == mode for feature, mode in modes.items()) >= 3\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Calculate mode for the specified category\n",
    "    modes = calculate_modes(df_copy, source_cat, features)\n",
    "\n",
    "    # Identify rows in target category that match the mode of source category\n",
    "    matching_condition = df_copy[df_copy['Processed food in diet'] == target_cat].apply(lambda row: matches_modes(row, modes), axis=1)\n",
    "    matching_rows_indices = matching_condition[matching_condition].index\n",
    "\n",
    "    # Modify 'Processed food in diet' for these rows in df_copy\n",
    "    df_copy.loc[matching_rows_indices, 'Processed food in diet'] = source_cat\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "# Usage example\n",
    "updated_df = update_food_category_based_on_modes(df_org2, 'Rarely/Never', 'Once a day', \n",
    "                                                 ['Frequency of getting a good nights sleep', \n",
    "                                                  'Frequency of doing exercise', \n",
    "                                                  'Frequency of Socializing'])\n",
    "\n",
    "# Check the modified distribution\n",
    "print(updated_df['Processed food in diet'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_org2['Processed food in diet'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rarely/Never           154981\n",
      "A few times a month    125715\n",
      "A few times a week      85120\n",
      "Once a day              19340\n",
      "Several times a day     16526\n",
      "Name: Processed food in diet, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def update_food_category_based_on_modes(df, source_cat, target_cat, features):\n",
    "    \"\"\"\n",
    "    Updates 'Processed food in diet' category in the DataFrame based on mode matching.\n",
    "    \n",
    "    :param df: DataFrame to be processed.\n",
    "    :param source_cat: The category to analyze for mode (e.g., 'Rarely/Never').\n",
    "    :param target_cat: The category to update to (e.g., 'Once a day').\n",
    "    :param features: List of features to calculate mode and match against.\n",
    "    :return: DataFrame with updated 'Processed food in diet' values.\n",
    "    \"\"\"\n",
    "    def calculate_modes(dataframe, category, feature_list):\n",
    "        category_df = dataframe[dataframe['Processed food in diet'] == category]\n",
    "        return {feature: category_df[feature].mode()[0] for feature in feature_list}\n",
    "\n",
    "    def matches_modes(row, modes):\n",
    "        return sum(row[feature] == mode for feature, mode in modes.items()) >= 3\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Calculate mode for the specified category\n",
    "    modes = calculate_modes(df_copy, source_cat, features)\n",
    "\n",
    "    # Identify rows in target category that match the mode of source category\n",
    "    matching_condition = df_copy[df_copy['Processed food in diet'] == target_cat].apply(lambda row: matches_modes(row, modes), axis=1)\n",
    "    matching_rows_indices = matching_condition[matching_condition].index\n",
    "\n",
    "    # Modify 'Processed food in diet' for these rows in df_copy\n",
    "    df_copy.loc[matching_rows_indices, 'Processed food in diet'] = source_cat\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "# Usage example\n",
    "updated_df = update_food_category_based_on_modes(df_org2, 'Rarely/Never', 'Once a day', \n",
    "                                                 ['Frequency of getting a good nights sleep', \n",
    "                                                  'Frequency of doing exercise', \n",
    "                                                  'Frequency of Socializing'])\n",
    "\n",
    "# Check the modified distribution\n",
    "print(updated_df['Processed food in diet'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71506\n"
     ]
    }
   ],
   "source": [
    "df=df_org2.copy()\n",
    "#df = df3\n",
    "\n",
    "#Age filter\n",
    "ages = ['18-24', '21-24', '18', '19', '20']\n",
    "df = df[df['Age'].isin(ages)]\n",
    "\n",
    "# Select only the columns with object type (commonly used for categorical features)\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "# Apply pd.get_dummies to the categorical features with a prefix\n",
    "encoded_features = pd.get_dummies(df[categorical_features])\n",
    "# Concatenate the encoded features with the original DataFrame (excluding the original categorical features)\n",
    "\n",
    "df = pd.concat([df.drop(columns=categorical_features), encoded_features], axis=1)\n",
    "\n",
    "df.columns.tolist()\n",
    "\n",
    "\n",
    "\n",
    "df = df[to_model_a].copy()\n",
    "print(len(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_empty_spaces; 0\n",
      "Rarely/Never           154981\n",
      "A few times a month    125715\n",
      "A few times a week      85120\n",
      "Once a day              19340\n",
      "Several times a day     16526\n",
      "Name: Processed food in diet, dtype: int64\n",
      "A few times a week     11113\n",
      "A few times a month     8436\n",
      "Rarely/Never            5209\n",
      "Once a day              3451\n",
      "Several times a day     2570\n",
      "Name: Processed food in diet, dtype: int64\n",
      "30779\n"
     ]
    }
   ],
   "source": [
    "#df_c=df_org2.copy()\n",
    "df_c = updated_df\n",
    "\n",
    "num_empty_spaces = df_c['Processed food in diet'].isna().sum()\n",
    "print(\"num_empty_spaces;\",num_empty_spaces)\n",
    "\n",
    "\n",
    "# Check the modified distribution\n",
    "print(df_c['Processed food in diet'].value_counts())\n",
    "\n",
    "# Country filter\n",
    "countries = ['United States','United Kingdom','Australia']\n",
    "df_c = df_c[df_c['Country'].isin(countries)]\n",
    "#print(df_c['Country'].value_counts())\n",
    "\n",
    "df_c = df_c.drop(columns='Country', axis=1)\n",
    "#print(df_c['Country'].value_counts())\n",
    "\n",
    "\n",
    "# Check the modified distribution\n",
    "print(df_c['Processed food in diet'].value_counts())\n",
    "\n",
    "#print(df['Country'].value_counts())\n",
    "\n",
    "# Select only the columns with object type (commonly used for categorical features)\n",
    "categorical_features = df_c.select_dtypes(include=['object']).columns\n",
    "# Apply pd.get_dummies to the categorical features with a prefix\n",
    "encoded_features = pd.get_dummies(df_c[categorical_features])\n",
    "# Concatenate the encoded features with the original DataFrame (excluding the original categorical features)\n",
    "\n",
    "df_c = pd.concat([df_c.drop(columns=categorical_features), encoded_features], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "df_c=df_c[to_model_c].copy()\n",
    "print(len(df_c))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countries and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_org2.copy()\n",
    "\n",
    "#Age filter\n",
    "ages = ['18-24', '21-24', '18', '19', '20']\n",
    "df = df[df['Age'].isin(ages)]\n",
    "\n",
    "# Country filter\n",
    "countries = ['United States','United Kingdom','Australia']\n",
    "df = df[df['Country'].isin(countries)]\n",
    "#print(df_c['Country'].value_counts())\n",
    "\n",
    "print(df['Country'].value_counts())\n",
    "\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "# Check the modified distribution\n",
    "print(df['Processed food in diet'].value_counts())\n",
    "\n",
    "\n",
    "# Select only the columns with object type (commonly used for categorical features)\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "# Apply pd.get_dummies to the categorical features with a prefix\n",
    "encoded_features = pd.get_dummies(df[categorical_features])\n",
    "# Concatenate the encoded features with the original DataFrame (excluding the original categorical features)\n",
    "\n",
    "df = pd.concat([df.drop(columns=categorical_features), encoded_features], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df=df[to_model_ac].copy()\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_org2.copy()\n",
    "\n",
    "# Select only the columns with object type (commonly used for categorical features)\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "# Apply pd.get_dummies to the categorical features with a prefix\n",
    "encoded_features = pd.get_dummies(df[categorical_features])\n",
    "# Concatenate the encoded features with the original DataFrame (excluding the original categorical features)\n",
    "\n",
    "df = pd.concat([df.drop(columns=categorical_features), encoded_features], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df=df[to_model].copy()\n",
    "print(len(df))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "X = df.drop(columns=['MHQ_Sign','Overall MHQ'], axis=1)\n",
    "\n",
    "# classification\n",
    "y = df['MHQ_Sign']\n",
    "# regressioin\n",
    "y_regression = df['Overall MHQ']\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y_regression, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"/Users/jerzybala/Desktop/data_causal_all_UPF_Age_18-24 and Anglosaxon_behavior_change.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['UPF_Social1'] = X['Processed food in diet_Rarely/Never'] + X['Frequency of Socializing_Once a week'] + X['Frequency of Socializing_Several days a week']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8121074290664934\n",
      "F1 Score: 0.8863264102732097\n",
      "Precision: 0.8264907135874878\n",
      "Recall: 0.9555021895747987\n",
      "AUC: 0.839543874909908\n"
     ]
    }
   ],
   "source": [
    "par1 = {\n",
    "    'n_estimators': 200, \n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 10, \n",
    "    'min_child_weight': 1, \n",
    "    'gamma': 0.01, \n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "# Initialize XGBoost classifier and train\n",
    "\n",
    "model_C = xgb.XGBClassifier(**par1)\n",
    "model_C.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions = model_C.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "auc = roc_auc_score(y_test, model_C.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"AUC: {auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# gs = GridSearchCV(XGBClassifier(), \n",
    "#                   param_grid, \n",
    "#                   scoring='accuracy',\n",
    "#                   cv=5)\n",
    "                  \n",
    "# gs.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# print(gs.best_params_)\n",
    "# print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize XGBoost regressor and train\n",
    "#model = xgb.XGBRegressor()\n",
    "# X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y_regression, test_size=0.3, random_state=42)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "#model_R = xgb.XGBRegressor()\n",
    "\n",
    "model_R = xgb.XGBRegressor(\n",
    "n_estimators=500,\n",
    "learning_rate=0.1,\n",
    "max_depth=6,\n",
    "min_child_weight=1,\n",
    "gamma=0.2,\n",
    "subsample=0.4,\n",
    "colsample_bytree=0.8,\n",
    "#reg_alpha=10,\n",
    "reg_lambda=0.1\n",
    ")\n",
    "\n",
    "model_R.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Separate predictions based on the sign of y_test\n",
    "predictions = model_R.predict(X_test_reg)\n",
    "\n",
    "mse = mean_squared_error(y_test_reg, predictions)\n",
    "rmse = math.sqrt(mse)\n",
    "r2 = r2_score(y_test_reg, predictions)\n",
    "mae = mean_absolute_error(y_test_reg, predictions)\n",
    "\n",
    "print('mae:', mae)\n",
    "print('rmse:',rmse)\n",
    "print('r2:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:11:29] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "baseline_shap_values = shap.TreeExplainer(model_C).shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:18:27] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n"
     ]
    }
   ],
   "source": [
    "variant1_shap_values = shap.TreeExplainer(model_C).shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer_C = shap.Explainer(model_C)\n",
    "shap_values_C = explainer_C(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shap_values_C_df = pd.DataFrame(shap_values_C.values, columns=shap_values_C.feature_names)\n",
    "shap_values_C_df.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True False\n",
      " False  True False False False False  True  True  True False False  True\n",
      "  True  True False  True False  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n"
     ]
    }
   ],
   "source": [
    "baseline_ranking = np.abs(baseline_shap_values).mean(0).argsort()\n",
    "variant1_ranking = np.abs(variant1_shap_values).mean(0).argsort()\n",
    "print(baseline_ranking == variant1_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Specify the plot size directly in the SHAP summary_plot function\n",
    "shap.summary_plot(shap_values_C, X_train, show=False, plot_size=(16,10), max_display=50)  # Adjust the size (width, height) as needed\n",
    "\n",
    "plt.title(f'SHAP Summary Plot for Classification Age=18-24 and Core Anglosphere > UPF more Raerly')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 SHAP value changed by 7.053371518850327e-05\n"
     ]
    }
   ],
   "source": [
    "modified_feature = 0 \n",
    "orig_shap = np.abs(baseline_shap_values[:, modified_feature]).mean()\n",
    "new_shap = np.abs(variant1_shap_values[:, modified_feature]).mean()\n",
    "print(f\"{modified_feature} SHAP value changed by {new_shap - orig_shap}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the training set predictions\n",
    "#  takes too long to run\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Assuming shap_values_C is a numpy array\n",
    "sampled_indices = np.random.choice(shap_values_C.shape[0], size=20000, replace=False)\n",
    "sampled_shap_values_C = shap_values_C[sampled_indices]\n",
    "\n",
    "shap.plots.force(sampled_shap_values_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SHAP dependence plot to show the effect of a single feature across the whole dataset\n",
    "shap.dependence_plot('Processed food in diet_Rarely/Never', shap_values_C.values, X_train, interaction_index=\"Frequency of Socializing_Rarely/Never\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the effects of all the features\n",
    "shap.plots.beeswarm(shap_values_C,max_display=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from shap import Explainer\n",
    "\n",
    "shap.force_plot(\n",
    "    shap.Explainer.expected_value[1], shap_values_C[1][:1000, :], X_train.iloc[:1000, :]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[X_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_R = shap.Explainer(model_R)\n",
    "shap_values_R = explainer_R(X_train_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Load SHAP values from each model\n",
    "baseline_shap_values = shap.TreeExplainer(baseline_model).shap_values(X)\n",
    "variant1_shap_values = shap.TreeExplainer(variant1_model).shap_values(X)\n",
    "variant2_shap_values = shap.TreeExplainer(variant2_model).shap_values(X)\n",
    "\n",
    "# Step 5 analysis\n",
    "\n",
    "# Summary plot \n",
    "shap.summary_plot(baseline_shap_values, X)\n",
    "shap.summary_plot(variant1_shap_values, X)\n",
    "\n",
    "# Compare feature ranking\n",
    "baseline_ranking = np.abs(baseline_shap_values).mean(0).argsort()\n",
    "variant1_ranking = np.abs(variant1_shap_values).mean(0).argsort()\n",
    "print(baseline_ranking == variant1_ranking)\n",
    "\n",
    "# Magnitude difference \n",
    "modified_feature = 0 \n",
    "orig_shap = np.abs(baseline_shap_values[:, modified_feature]).mean()\n",
    "new_shap = np.abs(variant1_shap_values[:, modified_feature]).mean()\n",
    "print(f\"{modified_feature} SHAP value changed by {new_shap - orig_shap}\")\n",
    "\n",
    "# Step 6 analysis\n",
    "corr_matrix = np.corrcoef(baseline_shap_values, rowvar=False) \n",
    "mod_corr_matrix = np.corrcoef(variant1_shap_values, rowvar=False)\n",
    "changed_corrs = np.nonzero(np.abs(corr_matrix - mod_corr_matrix) > threshold) \n",
    "print(f\"Modifying feature {modified_feature} affected dependencies with: {changed_corrs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'df' is your DataFrame with X and Y\n",
    "# Replace 'df' with the name of your DataFrame\n",
    "# Ensure your target column is named 'target'\n",
    "\n",
    "def calculate_information_gain(X,y):\n",
    "  \n",
    "    # Calculating mutual information\n",
    "    mutual_info = mutual_info_classif(X, y)\n",
    "\n",
    "    # Creating a DataFrame for easier visualization\n",
    "    info_gain_df = pd.DataFrame(mutual_info, index=X.columns, columns=['Information Gain'])\n",
    "    \n",
    "    # Sorting the DataFrame based on information gain\n",
    "    sorted_info_gain = info_gain_df.sort_values(by='Information Gain', ascending=False)\n",
    "\n",
    "    return sorted_info_gain\n",
    "\n",
    "#Example usage:\n",
    "sorted_info_gain = calculate_information_gain(X,y)\n",
    "print(sorted_info_gain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "#Example usage:\n",
    "sorted_info_gain = calculate_information_gain(X,y)\n",
    "print(tabulate(sorted_info_gain, headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
